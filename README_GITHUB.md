# 🎥 Audio Transcription & Sentiment Analysis Pipeline

This project consists of two Python programs:

1. **Part 1** - Extracts audio from video files, performs speech-to-text transcription, and classifies sentiment for each spoken segment.
2. **Part 2** - Visualizes the transcription data using meaningful plots.

---

## 📁 Part 1: Transcription & Sentiment Extraction

This notebook processes all video files placed in the `input_videos/` directory:

- 🎬 Extracts audio using `moviepy`
- ⏱ Splits audio into 5-second chunks using `pydub`
- 🧠 Transcribes speech using OpenAI's `whisper` model
- 😃 Analyzes sentiment using `transformers` (`distilbert-base-uncased-finetuned-sst-2-english`)
- 🧾 Outputs a `.csv` with `timestamp`, `transcription`, and `sentiment` columns in `output_data/`

### To Run:
```bash
python Part1_Transcription_Pipeline.ipynb
```

---

## 📊 Part 2: Visualization of Transcription Data

This notebook takes the `.csv` generated by Part 1 and displays:

1. 📊 Histogram of **word count per 5-second bucket**
2. 😊 Bar chart of **sentiment distribution**
3. 📈 Line plot of **sentiment trend over time**

### To Run:
Open the notebook:
```bash
Part2_Visualization.ipynb
```
Replace `"your_csv_file.csv"` with your actual output file from `output_data/`.

---

## 📂 Folder Structure

```
project/
├── input_videos/            # Your raw video files (e.g., .mp4)
├── output_data/             # Generated CSV files with transcription + sentiment
├── Part1_Transcription_Pipeline.ipynb
├── Part2_Visualization.ipynb
├── requirements.txt
└── README.md
```

---

## How It Was Tested

- Tested with short `.mp4` video files containing spoken English
- Whisper used in CPU fallback mode (`FP32`) if GPU unavailable
- Output validated via CSV inspection and visualizations

---

## 📋 Requirements

Install all dependencies with:

```bash
pip install -r requirements.txt
```

### Libraries Used:
- `pandas`
- `moviepy`
- `pydub`
- `whisper`
- `transformers`
- `torch`
- `matplotlib`
- `seaborn`

---

## 💡 Potential Extensions

- Speaker diarization
- Real-time inference with streaming input
- Interactive Streamlit dashboard

---

## 🧠 Author

> Prepared by [Your Name] for a screener submission — Audio/NLP & Data Visualization challenge.
